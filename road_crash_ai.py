# -*- coding: utf-8 -*-
"""road-crash-ai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1U0_k4Frq4j4gQK-s1oM-s8ocEzCT2Vyv
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install required packages
!pip install opencv-python tensorflow keras numpy matplotlib

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv3D, MaxPooling3D, Flatten, Dense,
                                    TimeDistributed, LSTM, BatchNormalization)
from tensorflow.keras.callbacks import ModelCheckpoint

# Set your paths (update these)
VIDEO_TRAIN_PATH = '/content/drive/MyDrive/A/train'
VIDEO_TEST_PATH = '/content/drive/MyDrive/A/test'

# Parameters
SEQ_LENGTH = 15  # Number of frames per sequence
IMG_HEIGHT, IMG_WIDTH = 224, 224
BATCH_SIZE = 8
EPOCHS = 15

def extract_frames(video_path, num_frames=SEQ_LENGTH):
    """Extract frames from video and preprocess"""
    frames = []
    cap = cv2.VideoCapture(video_path)

    while len(frames) < num_frames:
        ret, frame = cap.read()
        if not ret:
            break
        frame = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))
        frame = frame / 255.0  # Normalize
        frames.append(frame)

    cap.release()
    return np.array(frames)

def load_video_dataset(directory):
    """Load videos and labels from directory structure"""
    classes = sorted(os.listdir(directory))
    X, y = [], []

    for label, class_name in enumerate(classes):
        class_dir = os.path.join(directory, class_name)
        for video_file in os.listdir(class_dir):
            video_path = os.path.join(class_dir, video_file)
            frames = extract_frames(video_path)
            if len(frames) == SEQ_LENGTH:  # Only use complete sequences
                X.append(frames)
                y.append(label)

    return np.array(X), np.array(y)

# Load datasets
print("Loading training videos...")
X_train, y_train = load_video_dataset(VIDEO_TRAIN_PATH)
print("Loading test videos...")
X_test, y_test = load_video_dataset(VIDEO_TEST_PATH)

# Model Architecture (3D CNN + LSTM)
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import TimeDistributed, Conv2D, BatchNormalization, MaxPooling2D, Flatten, LSTM, Dense

model = Sequential([
    # TimeDistributed allows applying 2D layers to each frame
    TimeDistributed(Conv2D(16, (3,3), activation='relu',
                   input_shape=(SEQ_LENGTH, IMG_HEIGHT, IMG_WIDTH, 3))),
    TimeDistributed(BatchNormalization()),
    TimeDistributed(MaxPooling2D(2,2)),

    TimeDistributed(Conv2D(32, (3,3), activation='relu')),
    TimeDistributed(BatchNormalization()),
    TimeDistributed(MaxPooling2D(2,2)),

    TimeDistributed(Flatten()),

    # LSTM for temporal modeling
    LSTM(64, return_sequences=False),
    Dense(1, activation='sigmoid')  # Binary classification
])

model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Train the model
checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)
history = model.fit(X_train, y_train,
                    validation_data=(X_test, y_test),
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE,
                    callbacks=[checkpoint])

# After your training code, add these evaluation plots

# 1. Training vs. Validation Loss Curve
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Training vs. Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

# 2. Training vs. Validation Accuracy Curve
plt.subplot(1, 2, 2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training vs. Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.tight_layout()
plt.show()

# 3. Confusion Matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import seaborn as sns

# Make predictions
y_pred = model.predict(X_test)
y_pred_classes = (y_pred > 0.5).astype(int)  # Convert probabilities to binary classes

# Generate confusion matrix
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(6, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Non-Accident', 'Accident'],
            yticklabels=['Non-Accident', 'Accident'])
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# 4. ROC Curve & AUC Score
from sklearn.metrics import roc_curve, auc, roc_auc_score

fpr, tpr, thresholds = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# 5. Precision-Recall Curve (especially important for imbalanced data)
from sklearn.metrics import precision_recall_curve, average_precision_score

precision, recall, _ = precision_recall_curve(y_test, y_pred)
average_precision = average_precision_score(y_test, y_pred)

plt.figure(figsize=(8, 6))
plt.plot(recall, precision, color='blue', lw=2,
         label=f'Precision-Recall curve (AP = {average_precision:.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.ylim([0.0, 1.05])
plt.xlim([0.0, 1.0])
plt.legend(loc="lower left")
plt.show()

#Class Distribution Plot (Critical for Imbalanced Data)
plt.figure(figsize=(8, 4))
plt.bar(['Non-Accident', 'Accident'], [np.sum(y_test == 0), np.sum(y_test == 1)], color=['blue', 'red'])
plt.title('Class Distribution in Test Set')
plt.ylabel('Number of Samples')
plt.show()

# Error Analysis Samples (Visual Inspection)
# Show example false positives/negatives
false_positives = np.where((y_pred_classes == 1) & (y_test == 0))[0]
false_negatives = np.where((y_pred_classes == 0) & (y_test == 1))[0]

# Display sample frames from misclassified videos
def show_sample_frames(indices, title):
    plt.figure(figsize=(15, 5))
    plt.suptitle(title)
    num_videos_to_display = min(3, len(indices)) # limit to 3 or fewer videos
    for i, idx in enumerate(indices[:num_videos_to_display]):  # Show first 3 examples (or fewer)
        sample_frames = X_test[idx]
        num_frames_to_display = min(3, len(sample_frames[::SEQ_LENGTH//3])) # Display 3 frames or fewer
        for j, frame in enumerate(sample_frames[::SEQ_LENGTH//3][:num_frames_to_display]):  # Show 3 frames per video
            plt.subplot(num_videos_to_display, num_frames_to_display, i*num_frames_to_display + j + 1) # Update subplot indexing
            plt.imshow(frame)
            plt.axis('off')
    plt.tight_layout()
    plt.show()

if len(false_positives) > 0:
    show_sample_frames(false_positives, "False Positive Examples (Predicted Accident, Actual Non-Accident)")

if len(false_negatives) > 0:
    show_sample_frames(false_negatives, "False Negative Examples (Predicted Non-Accident, Actual Accident)")

#Threshold Optimization Plot (For Binary Classification)
from sklearn.metrics import f1_score

thresholds = np.linspace(0, 1, 50)
f1_scores = [f1_score(y_test, (y_pred > t).astype(int)) for t in thresholds]

plt.figure(figsize=(8, 4))
plt.plot(thresholds, f1_scores)
plt.title('F1 Score vs. Classification Threshold')
plt.xlabel('Threshold')
plt.ylabel('F1 Score')
plt.grid()
plt.show()

# Per-Class Metrics Bar Plot
from sklearn.metrics import classification_report

report = classification_report(y_test, y_pred_classes, output_dict=True)
metrics = ['precision', 'recall', 'f1-score']

plt.figure(figsize=(10, 5))
for i, metric in enumerate(metrics):
    plt.bar([f'Class 0 ({metric})', f'Class 1 ({metric})'],
            [report['0'][metric], report['1'][metric]],
            alpha=0.6)
plt.title('Per-Class Metrics')
plt.ylabel('Score')
plt.ylim(0, 1)
plt.show()

# Plot results
plt.plot(history.history['accuracy'], label='Train Acc')
plt.plot(history.history['val_accuracy'], label='Val Acc')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.show()

# Save model to Drive
model.save('/content/drive/MyDrive/AccidentDetection/video_model85-2accupdate.h5')

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Install TensorFlow (if not already installed)
!pip install tensorflow

# Import necessary libraries
from tensorflow.keras.models import load_model
import os

# Path to your model in Google Drive
# Replace with your actual path
model_path ='/content/drive/MyDrive/AccidentDetection/video_model85-2accupdate.h5'

# Verify the file exists
if os.path.exists(model_path):
    print(f"Model found at: {model_path}")

    # Load the model
    model = load_model(model_path)

    # Display the model summary
    model.summary()
else:
    print("Error: Model file not found. Please check the path.")

from google.colab import drive
drive.mount('/content/drive')

# Import libraries
from tensorflow.keras.models import load_model
import cv2
import numpy as np
from google.colab.patches import cv2_imshow
import os

# Load the saved model
model_path = '/content/drive/MyDrive/AccidentDetection/video_model85-2accupdate.h5'  # Update this path
if os.path.exists(model_path):
    model = load_model(model_path)
    print("Model loaded successfully.")
else:
    raise FileNotFoundError(f"Model file not found at: {model_path}")

# Path to the folder containing videos
video_folder = "/content/drive/MyDrive/T2"  # Update this path
print(f"Video folder set to: {video_folder}")

# Check if the folder exists
if not os.path.exists(video_folder):
    raise FileNotFoundError(f"Video folder does not exist at: {video_folder}")
print("Video folder exists.")

# Function to test the model on a new video
def test_new_video(model, video_path, frames_per_second=5, sequence_length=20):
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"Error: Could not open video {video_path}")
        return

    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_interval = int(fps / frames_per_second)
    frame_count = 0
    frames = []  # Store frames for the sequence

    while True:
        ret, frame = cap.read()
        if not ret:
            print("End of video or failed to read frame.")
            break

        # Extract frames at the specified interval
        if frame_count % frame_interval == 0:
            # Preprocess the frame
            resized_frame = cv2.resize(frame, (224, 224))  # Model expects 224x224
            normalized_frame = resized_frame / 255.0
            frames.append(normalized_frame)

            # When we have enough frames for a sequence
            if len(frames) == sequence_length:
                input_sequence = np.array(frames)
                input_sequence = np.expand_dims(input_sequence, axis=0)  # Add batch dimension

                # Make prediction
                prediction = model.predict(input_sequence)
                probability = prediction[0][0]
                label = "Accident" if probability > 0.5 else "No Accident"
                confidence = probability if label == "Accident" else 1 - probability

                # Display results on frame
                cv2.putText(frame,
                          f"{label} ({confidence:.2f})",
                          (50, 50),
                          cv2.FONT_HERSHEY_SIMPLEX,
                          1,
                          (0, 255, 0),
                          2)

                # Show the frame
                cv2_imshow(frame)

                # Remove oldest frame to maintain sequence length
                frames.pop(0)

        frame_count += 1

    cap.release()
    print(f"Finished processing video: {os.path.basename(video_path)}")

# Process all video files in the folder
for video_file in sorted(os.listdir(video_folder)):
    if video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv', '.flv')):
        video_path = os.path.join(video_folder, video_file)
        print(f"\nProcessing video: {video_file}")
        test_new_video(model, video_path)
    else:
        print(f"Skipping non-video file: {video_file}")